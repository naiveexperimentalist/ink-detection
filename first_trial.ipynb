{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aa3975f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "TRAIN_SET = 1\n",
    "SCAN_DEPTH = 16\n",
    "\n",
    "tr_dirname = 'train/'\n",
    "tr_set_dirname = os.path.join(tr_dirname, str(TRAIN_SET))\n",
    "tr_img_dirname = os.path.join(tr_set_dirname, 'surface_volume')\n",
    "tr_images = sorted([os.path.join(tr_img_dirname, filename) for filename in os.listdir(tr_img_dirname) if filename[-3:]=='tif'][:SCAN_DEPTH])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cf1d0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.array(Image.open(os.path.join(tr_set_dirname, \"mask.png\")).convert('1'))\n",
    "labels = np.array(Image.open(os.path.join(tr_set_dirname, \"inklabels.png\")).convert('1'))\n",
    "images = np.array([np.array(Image.open(filename), dtype=np.float32)/65535.0 for filename in tr_images]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cace7a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, data, mask, labels, px_offset=10, img_depth=4,\n",
    "                 include_rect=None, exclude_rect=None,\n",
    "                 batch_size=32, shuffle=True, name='', sample_count=0):\n",
    "        'Initialization'\n",
    "        self.px_offset = px_offset\n",
    "        self.include_rect = include_rect\n",
    "        self.exclude_rect = exclude_rect\n",
    "        self.dim = (2*self.px_offset+1, 2*self.px_offset+1, img_depth)\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.data = data\n",
    "        self.mask = mask\n",
    "        self.shuffle = shuffle\n",
    "        self.name = name\n",
    "        self.batches = dict()\n",
    "        self.cnt = sample_count\n",
    "        \n",
    "        self.data_gen = self.__data_generator()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return self.cnt // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if index not in self.batches.keys():\n",
    "            self.batches[index] = next(self.data_gen)\n",
    "        return self.batches[index]\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        pass\n",
    "\n",
    "    def __data_generator(self):\n",
    "        # Go through all pixels, collect next batch and return it\n",
    "        X = np.empty((self.batch_size, *self.dim, 1))\n",
    "        print(X.shape)\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "        batch_cnt = 0\n",
    "        cur_batch_cnt = 0\n",
    "        for pixel in zip(*np.where(self.mask==1)):            \n",
    "            if not DataGenerator.pixel_ok(pixel, self.px_offset, self.mask):\n",
    "                continue # Too close to the edge\n",
    "            if self.include_rect:\n",
    "                if DataGenerator.pixel_inside(pixel, self.include_rect):\n",
    "                    X[cur_batch_cnt, :, :, :, 0] = self.get_large_pixel(pixel)\n",
    "                    y[cur_batch_cnt] = self.labels[pixel[0],pixel[1]]\n",
    "                    cur_batch_cnt += 1\n",
    "            elif self.exclude_rect:\n",
    "                if not DataGenerator.pixel_inside(pixel, self.exclude_rect):\n",
    "                    X[cur_batch_cnt, :, :, :, 0] = self.get_large_pixel(pixel)\n",
    "                    y[cur_batch_cnt] = self.labels[pixel[0],pixel[1]]\n",
    "                    cur_batch_cnt += 1\n",
    "            else:\n",
    "                X[cur_batch_cnt, :, :, :, 0] = self.get_large_pixel(pixel)\n",
    "                y[cur_batch_cnt] = self.labels[pixel[0],pixel[1]]\n",
    "                cur_batch_cnt += 1\n",
    "            if cur_batch_cnt == self.batch_size:\n",
    "                print(f'returning batch #{batch_cnt}')\n",
    "                yield X, y.reshape((-1,1))\n",
    "                X = np.empty((self.batch_size, *self.dim, 1))\n",
    "                y = np.empty((self.batch_size), dtype=int)\n",
    "                cur_batch_cnt = 0\n",
    "                batch_cnt += 1                \n",
    "    \n",
    "    #staticmethod\n",
    "    def pixel_ok(pixel, offset, mask):\n",
    "        return (offset <= pixel[1] < mask.shape[1] - offset) and (offset <= pixel[0] < mask.shape[0] - offset)\n",
    "\n",
    "    #staticmethod\n",
    "    def pixel_inside(pixel, rect):\n",
    "        return (rect[0] <= pixel[1] <= rect[0] + rect[2]) and (rect[1] <= pixel[0] <= rect[1] + rect[3])\n",
    "    \n",
    "    def get_large_pixel(self, pixel):\n",
    "        return self.data[\n",
    "            pixel[0]-self.px_offset:pixel[0]+self.px_offset+1,\n",
    "            pixel[1]-self.px_offset:pixel[1]+self.px_offset+1,\n",
    "            :\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2c92a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0\n",
      "#3000000\n",
      "#6000000\n",
      "#9000000\n",
      "#12000000\n",
      "#15000000\n",
      "#18000000\n",
      "#21000000\n",
      "#24000000\n",
      "#27000000\n"
     ]
    }
   ],
   "source": [
    "PIXEL_SIZE = 16\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "VAL_RECT = (2064, 2864, 1000, 1000)\n",
    "# Determine the number of samples\n",
    "train_sample_cnt = 0\n",
    "val_sample_cnt = 0\n",
    "px_offset = PIXEL_SIZE // 2\n",
    "for c, pixel in enumerate(zip(*np.where(mask==1))):\n",
    "    if c % 3000000 == 0:\n",
    "        print(f'#{c}')\n",
    "    if not DataGenerator.pixel_ok(pixel, px_offset, mask):\n",
    "        continue # Too close to the edge\n",
    "    if DataGenerator.pixel_inside(pixel, VAL_RECT):\n",
    "        val_sample_cnt += 1\n",
    "    else:\n",
    "        train_sample_cnt += 1\n",
    "\n",
    "# Generators\n",
    "training_generator = DataGenerator(images, mask, labels, px_offset=px_offset,\n",
    "                                   img_depth=SCAN_DEPTH, exclude_rect=VAL_RECT,\n",
    "                                   batch_size=BATCH_SIZE, shuffle=True, name='TRAIN',\n",
    "                                   sample_count=train_sample_cnt)\n",
    "validation_generator = DataGenerator(images, mask, labels, px_offset=px_offset,\n",
    "                                     img_depth=SCAN_DEPTH, include_rect=VAL_RECT,\n",
    "                                     batch_size=BATCH_SIZE, shuffle=True, name='VAL',\n",
    "                                     sample_count=val_sample_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a66260b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 17, 16, 1)\n",
      "Metal device set to: Apple M2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 13:15:04.890583: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-03-21 13:15:04.890993: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Conv3D, MaxPooling3D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "real_px_size = 2*(PIXEL_SIZE//2) + 1\n",
    "input_shape = (real_px_size, real_px_size, SCAN_DEPTH, 1)\n",
    "print(input_shape)\n",
    "model = Sequential()\n",
    "model.add(Conv3D(16, kernel_size=(4, 4, 4), activation='relu', kernel_initializer='he_uniform', input_shape=input_shape))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 1)))\n",
    "model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "# model.add(MaxPooling3D(pool_size=(2, 2, 1)))\n",
    "model.add(Conv3D(16, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
    "# model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "model.compile(optimizer=Adam(learning_rate=0.01), loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13cabef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model on dataset\n",
    "model.fit(x=training_generator,\n",
    "          validation_data=validation_generator,\n",
    "          epochs=4,\n",
    "          use_multiprocessing=True,\n",
    "#           workers=3,\n",
    "          shuffle=False,\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e26f47a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
